{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nfrom PIL import Image\nimport pytesseract\nimport torch\nimport re\nfrom transformers import DonutProcessor, VisionEncoderDecoderModel,VisionEncoderDecoderConfig\nimport pytorch_lightning as pl\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nclass xtrac():\n    \"\"\"\n    Class for performing document extraction using a pre-trained model.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initialize the xtrac object.\n\n        Raises:\n            Exception: If an error occurs during model initialization.\n        \"\"\"\n        try:\n            self.image_size = [1280, 960]\n            self.max_length = 768\n            \n            self.config_path = \"model_params/config.pt\"\n            self.processor_path =\"model_params/processor.pt\"\n            self.model_path =\"model_params/model.pt\"\n            \n            self.config = torch.load(self.config_path)\n            self.processor = torch.load(self.processor_path)\n            self.model = VisionEncoderDecoderModel.from_pretrained(self.model_path, config = self.config)\n            # Change the decoder_start_token_id to 0.\n            \n            print(\"initialization done\")\n        except Exception as e:\n            print(\"Error occurred during model initialization:\", str(e))\n\n    def predict(self, image_path):\n        \"\"\"\n        Perform document extraction on the given image.\n\n        Args:\n            image (PIL.Image.Image): The input image in PIL format.\n\n        Returns:\n            str: Extracted document information in JSON format.\n\n        Raises:\n            Exception: If an error occurs during prediction.\n        \"\"\"\n        try:\n            self.image = Image.open(image_path)\n            self.rotated_image = self.image\n            self.rotation_angle = 0\n\n            try:\n                self.text = pytesseract.image_to_osd(self.image)\n                self.rotation_angle = int(re.search(\"(?<=Rotate: )\\d+\", self.text).group(0))\n                self.rotated_image = self.image.rotate(-self.rotation_angle, expand=True)\n            except pytesseract.pytesseract.TesseractError as e:\n                # Error occurred during OCR, handle as needed\n                print(\"OCR Error:\", str(e))\n\n            self.pixel_values = self.processor(images=self.rotated_image, return_tensors=\"pt\").pixel_values\n           \n            self.task_prompt = \"</s>\"\n            self.decoder_input_ids = self.processor.tokenizer(self.task_prompt,add_special_tokens=False,return_tensors=\"pt\")[\"input_ids\"]\n\n            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n            # self.device =  \"cpu\"\n            self.model = self.model.to(self.device)\n\n            # Adjust decoder_input_ids to match the batch size of pixel_values\n            self.decoder_input_ids = self.decoder_input_ids.expand(self.pixel_values.shape[0], -1)\n            self.outputs = self.model.generate(\n                self.pixel_values.to(self.device),\n                decoder_input_ids=self.decoder_input_ids.to(self.device),\n                max_length=self.model.decoder.config.max_position_embeddings,\n                early_stopping=True,\n                pad_token_id=self.processor.tokenizer.pad_token_id,\n                eos_token_id=self.processor.tokenizer.eos_token_id,\n                use_cache=True,\n                num_beams=1,\n                bad_words_ids=[[self.processor.tokenizer.unk_token_id]],\n                return_dict_in_generate=True,\n                output_scores=True,\n            )\n        \n            self.predictions = []\n            for seq in self.processor.tokenizer.batch_decode(self.outputs.sequences):\n                seq = seq.replace(self.processor.tokenizer.eos_token, \"\").replace(self.processor.tokenizer.pad_token, \"\")\n                seq = re.sub(r\"<.*?>\", \"\", seq, count=1).strip()\n                seq = re.sub(r\"(?<=>)|(?=</s_)\", \"\", seq, count=1).strip()\n                seq = self.processor.token2json(seq)\n                self.predictions.append(seq)\n                \n            self.ans = self.predictions[0]['text_sequence']\n            self.pattern = r\"<s_(\\w+)([^<]+)</s_\\1\"\n            self.matches = re.findall(self.pattern, self.ans)\n\n            # Create a dictionary to store the extracted key-value pairs\n            self.result_dict = {key.strip(): value.strip() for key, value in self.matches}\n\n            # Define a mapping of keys to their desired labels\n            self.key_mapping = {\n                \"payment_terms\": \"\",\n                \"date\": \"\",\n                \"currency\": \"\",\n                \"country\": \"\",\n                \"amount\": \"\",\n                \"Rname\": \"\",\n                \"Bname\": \"\"\n            }\n\n            # Print the extracted and transformed key-value pairs\n            for key, value in self.result_dict.items():\n                if key in self.key_mapping:\n                    self.key_mapping[key] =value\n            \n            return self.key_mapping\n                    \n        except Exception as e:\n            print(\"Error occurred during prediction:\", str(e))\n\n\n\n# Load your image\n# ins = xtrac()\n# print(ins.predict(image_path))","metadata":{"_uuid":"b0d401e7-0bc9-4311-8991-c5dfd1269dd1","_cell_guid":"f8b523d4-d984-4045-8c73-525421702162","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-28T11:26:37.271971Z","iopub.execute_input":"2023-08-28T11:26:37.272368Z","iopub.status.idle":"2023-08-28T11:26:38.148954Z","shell.execute_reply.started":"2023-08-28T11:26:37.272328Z","shell.execute_reply":"2023-08-28T11:26:38.147656Z"},"trusted":true},"execution_count":88,"outputs":[]}]}